{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio de Habla 3: Construcción de un Vocoder\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "1. Manipular y visualizar señales de voz en Julia.\n",
    "2. Realizar un análisis LPC de la señal de voz en Julia.\n",
    "3. Reconstruir señales usando filtros de reconstrucción.\n",
    "\n",
    "## Consejos para la Solución\n",
    "- Utiliza las convenciones de Julia para escribir código.\n",
    "- Copia el texto de los enunciados como parte (comentada) de un fichero de Julia para ejecutarlo.\n",
    "\n",
    "## Introducción: la Vocodificación LPC\n",
    "...\n",
    "\n",
    "## Ejercicio 1: Análisis Exploratorio de la Señal\n",
    "### Objetivo\n",
    "Determinar si la señal puede ser sujeta a codificación LPC efectiva.\n",
    "### Contenido\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lea y reproduzca la señal de voz proporcionada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using WAV\n",
    "señal, fs = wavread(\"confront.wav\")\n",
    "wavplay(señal,fs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Represente el sonido en el dominio del tiempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "using Plots #tengo que representarlo en tiempo \n",
    "d = (length(señal)-1)*(1/fs)\n",
    "t = 0:1/fs:d\n",
    "plot(t, señal, label = \"Señal de voz del fichero confront.wav\" , xlabel = \"Tiempo(segundos)\", ylabel = \"Amplitud\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Represente la energía localizada y la tasa de cruces por cero como función del tiempo, entramando la señal con diferentes tamaños de ventana y usando las primitivas desarrolladas en la práctica 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "using DSP\n",
    "using FFTW\n",
    "\n",
    "\n",
    "Tamaño = 7/1000\n",
    "N = round(Int, Tamaño*fs)\n",
    "t = (1:N)/fs\n",
    "\n",
    "#definimos las ventanas de hamming\n",
    "ventana_1 = hamming(N) # tamaño muy pequeño \n",
    "ventana_2 = hamming(400) # tamaño mediano \n",
    "ventana_3 = hamming(2000) # tamaño muy grande \n",
    "\n",
    "p1 = plot(t, ventana_1, label = \"ventana hamming 1\", xlabel = \"tamaño\")\n",
    "p2 = plot(ventana_2, label = \"ventana hamming 2\", xlabel = \"tamaño\")\n",
    "p3 = plot(ventana_3, label = \"ventana hamming 3\", xlabel = \"tamaño\")\n",
    "\n",
    "plot(p1,p2,p3, layaut=(3,1)) #para dibujar las ventanas hamming \n",
    "segmento = señal[15500:19500]\n",
    "\n",
    "# Función para calcular la energía con ventana\n",
    "\n",
    "function energia(s,h)\n",
    "    Lt = length(s) - length(h)\n",
    "    E = zeros(Lt)\n",
    "   \n",
    "    for n in 1:Lt\n",
    "      E[n] = sum((s[1+n:length(h)+n] .* h).^2)\n",
    "    end\n",
    "    return E\n",
    "end\n",
    "\n",
    "#Para sacar la energia localizada de cada una de ellas \n",
    "energia_1 = energia(segmento, ventana_1)\n",
    "energia_2 = energia(segmento, ventana_2)\n",
    "energia_3 = energia(segmento, ventana_3)\n",
    "\n",
    "plot(energia_1, title = \"Energía para diferentes ventanas Hamming\", label = \"Ventana 1\", xlabel = \"Número de ventanas\", ylabel = \"Energia\")\n",
    "plot!(energia_2, label = \"Ventana 2\")\n",
    "plot!(energia_3, label = \"Ventana 3\")\n",
    "function zcr(s, L)\n",
    "  # calcula la tasa de cruces por cero, de la señal s, en tramas de L longitud\n",
    "   \n",
    "    Zcr = zeros(length(s) - L + 1)\n",
    "   \n",
    "    for n in 2:length(s) - L\n",
    "      Zcr[n] = sum(0.5 / L * abs.(sign.(s[1 + n:L + n]) - sign.(s[n:L + n - 1])))\n",
    "    end\n",
    "   \n",
    "    Zcr[1] = Zcr[2]\n",
    "   \n",
    "    return Zcr\n",
    "end\n",
    "   \n",
    "function vozSS(s, h)\n",
    "    s = s .- sum(s) / length(s)\n",
    "    E = energia(s, h)\n",
    "    Zcr = zcr(s, length(h))\n",
    "   \n",
    "    plot1 = plot(s[1:length(s) - length(h)], title=\"Señal de voz\", xlabel = \"Muestras\", ylabel = \"Amplitud\", legend=false)\n",
    "    plot2 = plot(E, title=\"Energía\", xlabel = \"Muestras\", ylabel = \"E\", legend=false)\n",
    "    plot3 = plot(Zcr, title=\"Cruces por cero\", xlabel = \"Muestras\", ylabel = \"Tasa de cruces\", legend=false)\n",
    "    \n",
    "    plot(plot1, plot2, plot3, layout=(3,1), size=(800,600))\n",
    "end\n",
    "\n",
    "ventana_hamming = hamming(400)\n",
    "vozSS(segmento, ventana_hamming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ejercicio 2: Análisis de una trama\n",
    "### Objetivo\n",
    "Desarrollar el código de análisis-síntesis.\n",
    "### Contenido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "using Pkg\n",
    "Pkg.add(\"LPC\")\n",
    "using DSP\n",
    "using FFTW\n",
    "using WAV\n",
    "using Plots\n",
    "using ToeplitzMatrices\n",
    "using StatsBase\n",
    "using LinearAlgebra\n",
    "using LPC\n",
    "\n",
    "plotlyjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Seleccione y visualice en el tiempo y la frecuencia una trama sonora de la señal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confront, fs = wavread(\"./confront.wav\")\n",
    "\n",
    "d = (length(confront)-1)*(1/fs)\n",
    "t = 0:1/fs:d\n",
    "\n",
    "p1 = plot(t, confront, title=\"Signal (time)\")\n",
    "\n",
    "# calculate signal frecuency\n",
    "# contfront_fft = fftshift(fft(confront))\n",
    "# contfront_fft_module = abs.(contfront_fft)\n",
    "# frequencies = fftshift(fftfreq(length(t), fs))\n",
    "\n",
    "# p2 = plot(abs.(frequencies), contfront_fft_module, title=\"Signal (Frec)\", xlabel=\"Frecuencies (Hz)\", ylabel=\"|FFT|\")\n",
    "\n",
    "plot(p1, layout=(1,1))\n",
    "\n",
    "# visualizamos la señal en el tiempo para localizar una trama sonora\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualmente, vemos una trama sonora por ejemplo desde el segundo 0.5 hasta el 0.7 aproximadamente, vamos a comprobarlo entramando la señal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function aplicar_ventana(signal, fs)\n",
    "  duracion_trama = 0.02  # Duración de la trama en segundos\n",
    "  tamaño_trama = round(Int, duracion_trama * fs)  # Número de muestras en la trama\n",
    "  ventana = hamming(tamaño_trama)\n",
    "\n",
    "  datos_ventaneados = []\n",
    "\n",
    "  paso_muestras = round(Int, 0.02 * fs)  # Número de muestras para avanzar cada 20 ms\n",
    "\n",
    "  for i in 1:paso_muestras:length(signal)\n",
    "      if length(signal) < i+tamaño_trama-1\n",
    "        println(i)\n",
    "        trama = signal[i:length(signal)]\n",
    "        trama_ventaneada = trama .* ventana[1:length(trama)]\n",
    "        datos_ventaneados = vcat(datos_ventaneados, trama_ventaneada)\n",
    "      else\n",
    "        trama = signal[i:i+tamaño_trama-1]\n",
    "        trama_ventaneada = trama .* ventana\n",
    "        datos_ventaneados = vcat(datos_ventaneados, trama_ventaneada)\n",
    "      end\n",
    "  end\n",
    "\n",
    "  return convert(Vector{Float64}, datos_ventaneados)\n",
    "end\n",
    "\n",
    "confront, fs = wavread(\"./confront.wav\")\n",
    "d = (length(confront)-1)*(1/fs)\n",
    "t = 0:1/fs:d\n",
    "\n",
    "ventaneado = aplicar_ventana(confront, fs)\n",
    "\n",
    "println(length(ventaneado))\n",
    "println(length(confront))\n",
    "println(length(t))\n",
    "\n",
    "# Visualizar resultados\n",
    "plot(t, ventaneado, xlabel=\"Tiempo (s)\", ylabel=\"Amplitud\",\n",
    "   title=\"Señal Ventaneada de 'confront.wav'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function get_trama_by_window()\n",
    "d_ventana = 0.02\n",
    "n = fs * d_ventana\n",
    "N = Int(round(n))\n",
    "\n",
    "ventana = DSP.hamming(N)\n",
    "\n",
    "trama_sin_ventana = confront[5800+1:5800+N]\n",
    "\n",
    "trama = trama_sin_ventana .* ventana\n",
    "\n",
    "\n",
    "d = (length(trama)-1)*(1/fs)\n",
    "t = 0:1/fs:d\n",
    "\n",
    "p1 = plot(t, trama, title=\"Signal (time)\")\n",
    "\n",
    "# calculate signal frecuency\n",
    "trama_fft = fftshift(fft(trama))\n",
    "trama_fft_module = abs.(trama_fft)\n",
    "frequencies = fftshift(fftfreq(length(t), fs))\n",
    "\n",
    "p2 = plot(abs.(frequencies), trama_fft_module, title=\"Signal (Frec)\", xlabel=\"Frecuencies (Hz)\", ylabel=\"|FFT|\")\n",
    "\n",
    "plot(p1, p2, layout=(2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Obtenga la función de autocorrelación de la trama usando una función xcorr que reciba una trama y un orden y obtenga el vector de autocorrelación de ese orden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function autocorrelacion_orden(trama, orden)\n",
    "\n",
    "  autocorrelacion = xcorr(trama, trama)\n",
    "\n",
    "  orden = min(orden, length(autocorrelacion) - 1)\n",
    "\n",
    "  autocorrelacion_orden = autocorrelacion[length(trama) + 1 : length(trama) + orden + 1]\n",
    "\n",
    "  return autocorrelacion, autocorrelacion_orden\n",
    "end\n",
    "\n",
    "function sonido_sonoro_enventanado()\n",
    "  \n",
    "  N = 220\n",
    "  trama_sin_ventana = confront[9600:9600+N]     # trama sonora\n",
    "\n",
    "  trama_enventanada = aplicar_ventana(trama_sin_ventana, fs)\n",
    "\n",
    "  return trama_enventanada\n",
    "end\n",
    "\n",
    "N = 220\n",
    "\n",
    "trama_sin_ventana = confront[9600:9600+N]     # trama sonora\n",
    "\n",
    "trama_enventanada = aplicar_ventana(trama_sin_ventana, fs)\n",
    "\n",
    "order = 100\n",
    "autocorrelacion, acorr_order = autocorrelacion_orden(trama_enventanada, order)\n",
    "\n",
    "p1 = plot(trama_enventanada, title=\"Autocorrelation\")\n",
    "p2 = plot(acorr_order, title=\"Autocorrelation order $order\")\n",
    "\n",
    "plot(p1, p2, layout=(2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Genere la matriz R usando la biblioteca ToeplitzMatrices.jl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function generar_matriz_R(trama, orden)\n",
    "  # Calcula la autocorrelación de la trama hasta el orden deseado\n",
    "  autocorrelacion, autocorrelacion_orden_n = autocorrelacion_orden(trama, orden)\n",
    "  \n",
    "  # Genera la matriz toeplitz a partir del vector de autocorrelación\n",
    "  matriz_R = Toeplitz(autocorrelacion_orden_n, autocorrelacion_orden_n)\n",
    "  return matriz_R\n",
    "end\n",
    "\n",
    "trama = sonido_sonoro_enventanado()\n",
    "orden_autocorrelacion = 10\n",
    "\n",
    "matriz_R = generar_matriz_R(trama, orden_autocorrelacion)\n",
    "\n",
    "# show matrix\n",
    "# show(IOContext(stdout, :limit=>false), MIME\"text/plain\"(), matriz_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Obtenga los coeficientes de predicción lineal usando el sistema anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function calcular_coeficientes(trama, orden)\n",
    "\n",
    "  autocorrelacion, autocorrelacion_orden = autocorrelacion_trama(trama, orden)\n",
    "  \n",
    "  # R = generar_matriz_R(trama, orden)[1:end-1, 1:end-1]\n",
    "  R = generar_matriz_R(trama, orden)\n",
    "\n",
    "  R_prima = R[1:end-1, 1:end-1] # llegamos hasta p-1\n",
    "\n",
    "  r =  R[1,2:end] # from 1 to p\n",
    "\n",
    "  matriz_r = reshape(r, (length(r), 1))\n",
    "\n",
    "  # show(IOContext(stdout, :limit=>false), MIME\"text/plain\"(), R_prima)\n",
    "  # show(IOContext(stdout, :limit=>false), MIME\"text/plain\"(), matriz_r)\n",
    "\n",
    "  ak = R_prima \\ matriz_r\n",
    "  \n",
    "  return ak[:,1]\n",
    "end\n",
    "\n",
    "trama = sonido_sonoro_enventanado()\n",
    "orden_autocorrelacion = 40\n",
    "\n",
    "ak = calcular_coeficientes(trama, orden_autocorrelacion)\n",
    "plot(ak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeficientes ak a partir de la funcion lpc de DSP.jl\n",
    "\n",
    "trama = sonido_sonoro_enventanado()\n",
    "orden_autocorrelacion = 40\n",
    "\n",
    "aks, prediction_err = lpc(trama, orden_autocorrelacion, LPCLevinson())\n",
    "print(prediction_err)\n",
    "plot(aks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ejercicio 3: Síntesis de una trama\n",
    "### Objetivo\n",
    "Depurar el código de análisis-síntesis.\n",
    "### Contenido\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Obtenga, para la trama dada, el error de predicción como una señal, filtrando la trama a través del filtro FIR inverso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST FUNCTIONS\n",
    "\n",
    "function coeficientes_prediccion_lineal(sw, orden)\n",
    "  r = crosscov(sw, sw)\n",
    "  R = Toeplitz(r[1:orden],  r[1:orden])\n",
    "  a = R \\ r[2:orden+1]\n",
    "  return a\n",
    "end\n",
    "\n",
    "function error_prediccion(sw, orden)\n",
    "  # Obtén los coeficientes de predicción lineal\n",
    "  a = coeficientes_prediccion_lineal(sw, orden)\n",
    "  \n",
    "  # Filtro FIR inverso\n",
    "  b = [1.0, -a']  # Los coeficientes son [1, -a[1], -a[2], ..., -a[p]]\n",
    "  \n",
    "  # Filtra la trama original\n",
    "  print(\"this is b\")\n",
    "  println(b)\n",
    "  error = DSP.conv(b[2], sw)\n",
    "  \n",
    "  return error\n",
    "end\n",
    "\n",
    "sw = confront[5800:6200]\n",
    "orden = 2\n",
    "\n",
    "error = error_prediccion(sw, orden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USING FIRFilter from DSP.jl\n",
    "\n",
    "trama = confront[5800:6200]\n",
    "\n",
    "# Definir la frecuencia de muestreo\n",
    "fs = 10000  # Supongamos una frecuencia de muestreo de 10 kHz\n",
    "\n",
    "# Generar un vector de datos de ejemplo (reemplácelo con sus datos reales)\n",
    "output = randn(1000)\n",
    "\n",
    "# Filtro FIR de paso alto (150 Hz)\n",
    "fc_hp = 150\n",
    "B_hp = remez(1001, [0, fc_hp / (fs / 2), (fc_hp + 50) / (fs / 2), 1], [0, 1], weight=[1, 1])\n",
    "filtro_hp = DigitalFilter(B_hp, 1)\n",
    "\n",
    "# Filtro FIR de paso bajo (4000 Hz)\n",
    "fc_lp = 4000\n",
    "B_lp = remez(1000, [0, fc_lp / (fs / 2), (fc_lp + 50) / (fs / 2), 1], [1, 0], weight=[1, 1])\n",
    "filtro_lp = DigitalFilter(B_lp, 1)\n",
    "\n",
    "# Aplicar los filtros\n",
    "sal_1 = filter(filtro_hp, output)\n",
    "sal_2 = filter(filtro_lp, sal_1)\n",
    "\n",
    "# Mostrar resultados (solo para visualización, puedes omitir esta parte)\n",
    "plot(output, label=\"Original\", title=\"Filtrado FIR en Julia\")\n",
    "plot!(sal_1, label=\"Filtro Paso Alto (150 Hz)\")\n",
    "plot!(sal_2, label=\"Filtro Paso Bajo (4000 Hz)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trama = sonido_sonoro_enventanado()\n",
    "orden_autocorrelacion = 40\n",
    "\n",
    "ak = calcular_coeficientes(trama, orden_autocorrelacion)\n",
    "\n",
    "filt = filtfilt(ak, confront)\n",
    "\n",
    "plot(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another test\n",
    "\n",
    "\n",
    "# Obtener la señal original\n",
    "trama = sonido_sonoro_enventanado()\n",
    "a, e, rc = DSP.lpc_burg(confont, 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Sintetice la trama de voz analizada mediante el filtro de síntesis calculado en el apartado 1.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Inspeccione, auditivamente, en el tiempo y en la frecuencia las tramas de voz original y sintetizada. ¿Son correctos los coeficientes de análisis-síntesis?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ejercicio 4: Síntesis LPC\n",
    "### Objetivo\n",
    "Realizar el análisis-síntesis LPC de una elocución de voz.\n",
    "### Contenido\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Identificar si cada trama de voz es sonora o sorda usando tanto la tasa de cruces por cero como la energía localizada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostramos la señal en muestras normales para ver de que rango (visualmente) es sorda o sonora,\n",
    "# y lo comprobaremos posteriormente\n",
    "\n",
    "signal = confront\n",
    "plot(signal, xlabel=\"Muestras\", ylabel=\"Señal de audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serian por ejemplo, dos tramas sordas:\n",
    "* [1500:2000]\n",
    "* [8000:9000]\n",
    "\n",
    "Y tramas sonoras:\n",
    "* [6600:7600]\n",
    "* [16000:16600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruces por cero y energia de las tramas sordas\n",
    "\n",
    "sorda_1 = confront[1500:2000]\n",
    "sorda_2 = confront[8000:9000]\n",
    "\n",
    "function zcr(s, window)\n",
    "  # calcula la tasa de cruces por cero, de la señal s, en tramas de L longitud\n",
    "\n",
    "  L = length(window)\n",
    "  Zcr = zeros(length(s) - L + 1)\n",
    "\n",
    "  for n in 2:length(s) - L\n",
    "    Zcr[n] = sum(0.5 / L * abs.(sign.(s[1 + n:L + n]) - sign.(s[n:L + n - 1])))\n",
    "  end\n",
    "\n",
    "  Zcr[1] = Zcr[2]\n",
    "\n",
    "  return Zcr / L\n",
    "end\n",
    "\n",
    "function cruces_energia(signal, window)\n",
    "\n",
    "  print(\"test\")\n",
    "\n",
    "end\n",
    "\n",
    "function visualizar(trama)\n",
    "  N = 100 # tamaño de ventana\n",
    "  h_window = DSP.hamming(N)\n",
    "  Zcr = zcr(trama, h_window)\n",
    "\n",
    "  p1 = plot(trama)\n",
    "  p2 = plot(Zcr)\n",
    "\n",
    "  plot(p1, p2, layout=(2,1))\n",
    "end\n",
    "\n",
    "visualizar(sorda_1)\n",
    "visualizar(sorda_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos si una trama es sorda o sonora, y la tasa de cruces por 0 y energia, por partes.\n",
    "\n",
    "# funcion para la energia\n",
    "\n",
    "function energia(s,h)\n",
    "\n",
    "  # h - ventana de hamming\n",
    "  # s - segmento de la señal\n",
    "  # E = energia(s, h)\n",
    "  Lt = length(s) - length(h)\n",
    "  E = zeros(Lt)\n",
    "\n",
    "  d = (length(confront)-1)*(1/fs)\n",
    "  t = 0:1/fs:d\n",
    "\n",
    "  for n in 1:Lt\n",
    "    E[n] = sum((s[1+n:length(h)+n] .* h).^2)\n",
    "  end\n",
    "\n",
    "  # Gráfico\n",
    "  p1 = plot(t, s, title=\"Señal s\", xlabel=\"Muestras\", ylabel=\"s\", legend=false)\n",
    "  p2 = plot(E, title=\"Energía\", xlabel=\"Muestras\", ylabel=\"E\", legend=false)\n",
    "\n",
    "  plot(p1, p2, layout=(2, 1))\n",
    "end\n",
    "\n",
    "function enventanado(signal, hamming, position)\n",
    "  enventanada = signal .* hamming\n",
    "  plot(signal, label=\"Señal Original\")\n",
    "  plot!(enventanada, label=\"Señal Enventanada\", title=\"Señal Original y Enventanada\", xlabel=\"Muestras\", ylabel=\"s\", legend=true)\n",
    "end\n",
    "\n",
    "signal = confront\n",
    "trama = confront[12000:13000]\n",
    "h_window = DSP.hanning(length(trama))\n",
    "\n",
    "enventanado(trama, h_window, position)\n",
    "\n",
    "# energia(signal, h_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasa de cruces por cero\n",
    "include(\"functions.jl\")\n",
    "\n",
    "signal = confront\n",
    "segmento = confront[12000:14000]\n",
    "h_window = DSP.hamming(100)\n",
    "\n",
    "vozSS(segmento, h_window)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Calcular la frecuencia fundamental de las tramas sonoras, si puede, usando la FFT.\n",
    "3. De nuevo, calcule la frecuencia fundamental pero usando en este caso la autocorrelación. ¿En qué propiedad fundamental de la teoría de señales se basa este método? Para responder, reflexione acerca de lo que es la función de autocorrelación desarrollada más arriba.\n",
    "4. Encuentre una trama sorda y una trama sonora de su señal de voz como en 1.3 y calcule y visualice sus autocorrelaciones como en 2.2. Para la trama sonora, estime el tono fundamental como en 4.1\n",
    "5. Halle los espectros de las tramas seleccionadas y represéntelos para explorarlos.\n",
    "6. Construya una función que reciba una trama y devuelva todos los parámetros de análisis necesarios para re-sintetizar la trama.\n",
    "7. Construya una función que reciba todos los parámetros de análisis y reconstruya una trama de voz en el tiempo.\n",
    "8. Para toda la señal de voz s[n] diseñe e implemente un esquema de enventanado con ventanas de longitud N que se solapen un 50% de la longitud. Ayúdese de alguna referencia técnica si no entiende qué tiene que hacer. También, decida qué orden de filtro LPC va a usar...\n",
    "9. Sobre el diseño de enventanado anterior, cuando pase por una trama, analícela y sintetícela para construir una señal aproximada sZ[n].\n",
    "10. Compare s[n] y su aproximación sZ[n] visual y auditivamente. Investigue diferentes valores del orden del filtro. ¿Puede observar algún efecto en la señal reconstruida?\n",
    "\n",
    "## Ejercicio 5: Reflexión\n",
    "### Objetivo\n",
    "Aprender a descubrir y ser consciente de los resultados de aprendizaje propios.\n",
    "### Actividad\n",
    "Escriba un párrafo listando los conocimientos y destrezas adquiridos en esta práctica.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
